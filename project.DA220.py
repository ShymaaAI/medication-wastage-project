import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import joblib
import os
import json
from datetime import datetime

# --- ØªØ­Ù…ÙŠÙ„ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
DATA_PATH = "database/Untitled2.xlsx"

@st.cache_data
def load_and_prepare_data():
    df = pd.read_excel(DATA_PATH)
    df.columns = df.columns.str.strip().str.replace(r'\s+', '_', regex=True).str.replace('[^\w_]', '', regex=True)
    df.fillna("ØºÙŠØ± Ù…Ø­Ø¯Ø¯", inplace=True)

    response_mapping = {
        "Ù„Ø§ Ø£ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©": 1,
        "Ù„Ø§ Ø£ÙˆØ§ÙÙ‚": 2,
        "Ù…Ø­Ø§ÙŠØ¯": 3,
        "Ø£ÙˆØ§ÙÙ‚": 4,
        "Ø£ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©": 5
    }

    for col in df.columns:
        if df[col].dtype == 'object':
            unique_vals = df[col].dropna().unique()
            if set(unique_vals).intersection(set(response_mapping.keys())):
                df[col] = df[col].map(response_mapping).fillna(df[col])

    feature_cols = df.columns[6:].tolist()

    threshold = len(feature_cols) * 3.0

    X = df[feature_cols]
    df["Awareness_Level"] = X.sum(axis=1).apply(lambda x: 1 if x >= threshold else 0)
    y = df["Awareness_Level"]

    return df, X, y, feature_cols

df, X, y, feature_cols = load_and_prepare_data()

# --- ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ùˆ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ---
MODEL_PATH = "streamlit_app/medication_wastage_model.pkl"

def train_and_save_model():
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    joblib.dump(model, MODEL_PATH)
    return model

if os.path.exists(MODEL_PATH):
    model = joblib.load(MODEL_PATH)
else:
    model = train_and_save_model()

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
display_questions = [
    "Ø£Ø­Ø±Øµ Ø¹Ù„Ù‰ Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø­Ø³Ø¨ ÙˆØµÙØ© Ø§Ù„Ø·Ø¨ÙŠØ¨",
    "Ø£Ø´Ø§Ø±Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ù…Ø¹ Ø£Ø´Ø®Ø§Øµ Ø¢Ø®Ø±ÙŠÙ† Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©",
    "Ø£Ø´ØªØ±ÙŠ Ø£Ø¯ÙˆÙŠØ© Ø¨Ø¯ÙˆÙ† ÙˆØµÙØ© Ø·Ø¨ÙŠØ©",
    "Ø£Ù‚Ø±Ø£ Ø§Ù„Ù†Ø´Ø±Ø© Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ù…Ø¹ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡",
    "Ø£Ø®Ø¨Ø± Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø¨Ø£Ù† Ù„Ø¯ÙŠ Ù†ÙØ³ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù…Ø³Ø¨Ù‚Ù‹Ø§",
    "Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø¹Ù†Ø¯Ù…Ø§ ÙŠØµÙ Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø£Ø¯ÙˆÙŠØ© Ø£ÙƒØ«Ø±",
    "Ø£ÙØ¶Ù„ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ù„ÙŠ",
    "Ø£Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§",
    "Ø£Ø³ØªØ´ÙŠØ± Ø§Ù„ØµÙŠØ¯Ù„ÙŠ Ø¨Ø®ØµÙˆØµ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©",
    "Ø§Ù„ØªØ®Ù„Øµ Ø§Ù„Ø®Ø§Ø·Ø¦ Ù…Ù† Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ÙŠØ¶Ø± Ø§Ù„Ø¨ÙŠØ¦Ø©"
]

likert_options = ["Ù„Ø§ Ø£ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©", "Ù„Ø§ Ø£ÙˆØ§ÙÙ‚", "Ù…Ø­Ø§ÙŠØ¯", "Ø£ÙˆØ§ÙÙ‚", "Ø£ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©"]
mapping = {"Ù„Ø§ Ø£ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©":1, "Ù„Ø§ Ø£ÙˆØ§ÙÙ‚":2, "Ù…Ø­Ø§ÙŠØ¯":3, "Ø£ÙˆØ§ÙÙ‚":4, "Ø£ÙˆØ§ÙÙ‚ Ø¨Ø´Ø¯Ø©":5}

# --- ÙˆØ§Ø¬Ù‡Ø© Streamlit ---
st.set_page_config(page_title="Jordanians' Awareness of Medication Wastage", layout="centered")
st.title("ğŸ’Š ØªÙ‚ÙŠÙŠÙ… ÙˆØ¹ÙŠ Ø§Ù„Ø£Ø±Ø¯Ù†ÙŠÙŠÙ† Ø¨Ù‡Ø¯Ø± Ø§Ù„Ø£Ø¯ÙˆÙŠØ©")

name = st.text_input("Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„:")
student_id = st.text_input("Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠ:")

st.markdown("ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ Ø¨Ø¹Ù†Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¯Ù†Ø§Ù‡ Ø«Ù… Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„ØªÙ†Ø¨Ø¤.")

user_responses = []
with st.form("form"):
    for q in display_questions:
        answer = st.selectbox(q, likert_options)
        user_responses.append(mapping[answer])
    submitted = st.form_submit_button("ØªÙ†Ø¨Ø¤ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØ¹ÙŠ")

# --- ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø±Ø¯ÙˆØ¯ ÙÙŠ Ù…Ù„Ù JSON ---
def load_data():
    file_path = "database/responses_data.json"
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return []

def save_data(data):
    file_path = "database/responses_data.json"
    existing_data = load_data()
    for record in existing_data:
        if record["student_id"] == data["student_id"]:
            record.update(data)
            break
    else:
        existing_data.append(data)
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=4)

# --- Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---
if submitted:
    if not name.strip() or not student_id.strip():
        st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆØ§Ù„Ø±Ù‚Ù… Ø§Ù„Ø¬Ø§Ù…Ø¹ÙŠ.")
    else:
        avg_score = sum(user_responses) / len(user_responses)
        if avg_score >= 3.5:
            st.success("ğŸ‰ Ù„Ø¯ÙŠÙƒ ÙˆØ¹ÙŠ Ù…Ø±ØªÙØ¹ Ø¨Ù‡Ø¯Ø± Ø§Ù„Ø£Ø¯ÙˆÙŠØ©! Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„ØµØ­ÙŠ.")
            awareness = "Ù…Ø±ØªÙØ¹"
        else:
            st.warning("âš ï¸ Ù„Ø¯ÙŠÙƒ ÙˆØ¹ÙŠ Ù…Ù†Ø®ÙØ¶ Ø¨Ù‡Ø¯Ø± Ø§Ù„Ø£Ø¯ÙˆÙŠØ©. ÙŠÙÙØ¶Ù„ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø³Ù„ÙˆÙƒÙŠØ§ØªÙƒ Ù„ØªØ­Ø³ÙŠÙ†Ù‡.")
            awareness = "Ù…Ù†Ø®ÙØ¶"

        input_dict = {}
        for i in range(len(display_questions)):
            input_dict[feature_cols[i]] = user_responses[i]
        for i in range(len(display_questions), len(feature_cols)):
            input_dict[feature_cols[i]] = 3

        data_to_save = {
            "timestamp": datetime.now().isoformat(),
            "name": name,
            "student_id": student_id,
            "responses": input_dict,
            "awareness_level": awareness,
            "average_score": avg_score
        }
        save_data(data_to_save)
